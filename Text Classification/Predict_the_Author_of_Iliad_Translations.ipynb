{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NNl7SIMSkiAt"
   },
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7rzXhvXjkhU5"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_text as tf_text\n",
    "import numpy as np\n",
    "import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PXeE0DN5kktw"
   },
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9AeOS-nvyPpi",
    "outputId": "53618de8-2710-4be4-d762-970bd4ada03d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/illiad/cowper.txt\n",
      "\u001b[1m815980/815980\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/illiad/derby.txt\n",
      "\u001b[1m809730/809730\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/illiad/butler.txt\n",
      "\u001b[1m807992/807992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "data_url = 'https://storage.googleapis.com/download.tensorflow.org/data/illiad/'\n",
    "file_names = ['cowper.txt', 'derby.txt', 'butler.txt']\n",
    "dir_name = '/content/'\n",
    "\n",
    "dataset_dir = [tf.keras.utils.get_file(\n",
    "                    origin = data_url + file_name,\n",
    "                    fname = file_name,\n",
    "                    cache_dir = dir_name,\n",
    "                    cache_subdir = '',\n",
    "                ) for file_name in file_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ynqhl3FbkwSo"
   },
   "source": [
    "### Preprocess Data\n",
    "- Add labels\n",
    "- Combine all the data into one single dataset\n",
    "- Shuffle data to ensure uniformity during training/validation/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZUsuwLi3kvXS"
   },
   "outputs": [],
   "source": [
    "# label every dataset line\n",
    "labeled_ds = []\n",
    "for id, filepath in enumerate(dataset_dir):\n",
    "    text_ds = tf.data.TextLineDataset(filepath)\n",
    "    labeled_text = text_ds.map(lambda text_line: (text_line, tf.cast(id, dtype=tf.int64)))\n",
    "    labeled_ds.append(labeled_text)\n",
    "\n",
    "# Concatenate everything into a single dataset\n",
    "final_ds = labeled_ds[0]\n",
    "for ds in labeled_ds[1:]:\n",
    "    final_ds = final_ds.concatenate(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KiJqBC6NuV10"
   },
   "source": [
    "#### Shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KhkRNA4Fq482",
    "outputId": "455c9b6b-5bdd-40bb-b17b-22729c0cb5eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence [22]: taught to use the bow., Label: 2\n",
      "Sentence [43]: This said, he sat; and Atreus' godlike son,, Label: 1\n",
      "Sentence [39]: Is gone to Chrysa, and with her we send, Label: 0\n",
      "Sentence [67]: He cut the boar's throat as he spoke, whereon Talthybius whirled it, Label: 2\n",
      "Sentence [50]: Redden'd the east, then, thronging forth, all Troy, Label: 0\n",
      "Sentence [44]: Far off, the lowest abyss beneath the earth,, Label: 1\n",
      "Sentence [68]: homed stag or wild goat--he has taken shelter under rock or thicket,, Label: 2\n",
      "Sentence [46]: By Trojan hands, within their fleet they stood, Label: 0\n",
      "Sentence [43]: Didst to our bravest wrong, dishon'ring him, Label: 1\n",
      "Sentence [69]: by the ship of Achilles, and though it is now twelve days that he has, Label: 2\n"
     ]
    }
   ],
   "source": [
    "final_ds = final_ds.shuffle(buffer_size=50000, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "for text, label in final_ds.take(10):\n",
    "    t = str(np.char.decode(text.numpy()))\n",
    "    print(f\"Sentence [{len(t)}]: {t}, Label: {label.numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YNDb4VWOYzE7"
   },
   "source": [
    "## Create Vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MD8Otg83uwyB"
   },
   "source": [
    "#### Create tokenizer\n",
    "\n",
    "- Create custom tokenizer that lowercases and tokenizes the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I3VbZ3l6vOtx"
   },
   "outputs": [],
   "source": [
    "class MyTokenizer(tf.keras.Layer):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.tokenizer = tf_text.UnicodeScriptTokenizer()\n",
    "\n",
    "    def call(self, text):\n",
    "        lower_case_text = tf_text.case_fold_utf8(text)\n",
    "        result = self.tokenizer.tokenize(lower_case_text)\n",
    "        # A batch of text will return a RaggedTensor\n",
    "        if isinstance(result, tf.RaggedTensor):\n",
    "            result = result.to_tensor()\n",
    "        return result\n",
    "\n",
    "tokenizer = MyTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xJypS-jg0QJL",
    "outputId": "55e7f154-e2b7-4016-dd8a-3f5024e36361"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Sentence: [b'taught' b'to' b'use' b'the' b'bow' b'.']\n",
      "Label: 2\n"
     ]
    }
   ],
   "source": [
    "tokenized_ds = final_ds.map(lambda text, label: (tokenizer(text), label))\n",
    "\n",
    "for tokens, label in tokenized_ds.take(1):\n",
    "    break\n",
    "print(f\"Tokenized Sentence: {tokens}\")\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k5s1-Ayd1lG7"
   },
   "source": [
    "#### Configure dataset for optimized memory management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "undWLaDo1jlz"
   },
   "outputs": [],
   "source": [
    "tokenized_ds = tokenized_ds.cache().prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z3GMuwgz1-3w"
   },
   "source": [
    "### Create vocabulary\n",
    "\n",
    "- create a fequency dictionary with all the vocabulary.\n",
    "- sort tokens in the vocabulary by frequency.\n",
    "- keep the top VOCAB_SIZE tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vhz2pFRk2Bma"
   },
   "outputs": [],
   "source": [
    "vocab_count = collections.Counter()\n",
    "\n",
    "for batch, labels in tokenized_ds.ragged_batch(1000):\n",
    "    flat_batch = tf.reshape(batch, [-1]) # Flatten batch.\n",
    "    for token in flat_batch.numpy():\n",
    "        vocab_count[token] += 1\n",
    "\n",
    "VOCAB_SIZE = 10000\n",
    "vocabulary = [token for token, count in vocab_count.most_common(VOCAB_SIZE)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PFOfHJvK72wE",
    "outputId": "27e473a2-05c7-46b8-b296-75b8e1912736"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab entries: [b',', b'the', b'and', b\"'\", b'of', b'.', b'to', b'd', b';', b'his', b'he', b'in', b'with', b'a', b'him', b'-', b'from', b'for', b'but', b'i']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Vocab entries: {vocabulary[:20]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4a66-e5bZLm0"
   },
   "source": [
    "#### Assign ID to vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wx-RYVXOZO5V",
    "outputId": "36f7cd45-dcdf-410e-bce1-b14d847aae67"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(9,), dtype=int64, numpy=array([0, 1, 4, 4, 4, 3, 4, 4, 4])>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyVocabTable(tf.keras.Layer):\n",
    "    def __init__(self, vocabulary):\n",
    "        super().__init__()\n",
    "        self.keys = [''] + vocabulary\n",
    "        self.values = range(len(self.keys))\n",
    "\n",
    "        self.init = tf.lookup.KeyValueTensorInitializer(\n",
    "                        self.keys,\n",
    "                        self.values,\n",
    "                        key_dtype = tf.string,\n",
    "                        value_dtype= tf.int64,\n",
    "                    )\n",
    "        # <other term> -> bucket_id\n",
    "        # bucket_id will be between len(self.values) + num_oov_buckets - 1,\n",
    "        # calculated by: hash(<term>) % num_oov_buckets + vocab_size\n",
    "        num_oov_buckets = 1\n",
    "\n",
    "        # String to Id table that assigns out-of-vocabulary keys to hash buckets.\n",
    "        self.table = tf.lookup.StaticVocabularyTable(self.init, num_oov_buckets)\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.table.lookup(x)\n",
    "\n",
    "# Test\n",
    "myVocab = MyVocabTable(['a', 'b', 'c'])\n",
    "myVocab(tf.constant(['']+list('adgsclsd')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NnCywW24finN",
    "outputId": "48c97bab-f269-4126-b48a-f8fb15bdd7ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b\"this is Pepe, he said; and his 'godlike' son Achilles.\", shape=(), dtype=string)\n",
      "tf.Tensor(\n",
      "[b'this' b'is' b'pepe' b',' b'he' b'said' b';' b'and' b'his' b\"'\"\n",
      " b'godlike' b\"'\" b'son' b'achilles' b'.'], shape=(15,), dtype=string)\n",
      "tf.Tensor(\n",
      "[   66    45 10001     1    11    82     9     3    10     4   300     4\n",
      "    27    56     6], shape=(15,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "vocab_table = MyVocabTable(vocabulary)\n",
    "\n",
    "# Test\n",
    "text = tf.constant(\"this is Pepe, he said; and his 'godlike' son Achilles.\")\n",
    "print(text)\n",
    "tokenized_text = tokenizer(text)\n",
    "print(tokenized_text)\n",
    "token_ids = vocab_table(tokenized_text)\n",
    "print(token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nPkOoUI9ag4o"
   },
   "outputs": [],
   "source": [
    "preprocess_text = tf.keras.Sequential([\n",
    "                    tokenizer,\n",
    "                    vocab_table,\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WgSasZPvawwZ",
    "outputId": "537bac3b-2856-4a20-bef4-1a0cce4275e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[   66    45 10001     1    11    82     9     3    10     4   300     4\n",
      "    27    56     6], shape=(15,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "text = tf.constant(\"this is Pepe, he said; and his 'godlike' son Achilles.\")\n",
    "token_ids_v2 = preprocess_text(text)\n",
    "print(token_ids_v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ztbG6IRdKDb_"
   },
   "source": [
    "#### Create a dataset pipeline that will process text and encode the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JkwyyO7GJCTL",
    "outputId": "7747b10b-6f7c-4fc0-91ea-5f18d093c5e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1594    7 1595    2  309    6], shape=(6,), dtype=int64)\n",
      "tf.Tensor(2, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "encoded_ds = final_ds.map(lambda x, y: (preprocess_text(x), y))\n",
    "\n",
    "for ids, label in encoded_ds.take(1):\n",
    "    break\n",
    "\n",
    "print(ids)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iZ3w3Aa4J-1o"
   },
   "source": [
    "## Split Data\n",
    "\n",
    "\n",
    "- Combines consecutive elements of the input dataset into single padded batches.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "POpIWtuzfvGd"
   },
   "outputs": [],
   "source": [
    "VALIDATION_SIZE = int(49608 * 0.2)\n",
    "BUFFER_SIZE = 50000\n",
    "BATCH_SIZE = 64\n",
    "SEED = 42\n",
    "\n",
    "train_ds = encoded_ds.skip(VALIDATION_SIZE).shuffle(BUFFER_SIZE, SEED).padded_batch(BATCH_SIZE)\n",
    "validation_ds = encoded_ds.take(VALIDATION_SIZE).shuffle(BUFFER_SIZE, SEED).padded_batch(BATCH_SIZE)\n",
    "\n",
    "# Setup for Performance\n",
    "train_ds = train_ds.cache().prefetch(tf.data.AUTOTUNE)\n",
    "validation_ds = validation_ds.cache().prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xgQRxeTjiLk2",
    "outputId": "dea655ae-ffd9-42dc-c02c-a488c150db86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes X: (64, 19), Y: (64,)\n",
      "1st Element: [5432    4    8   25   79  123 4413    4   28 2156    1    0    0    0\n",
      "    0    0    0    0    0], Y: 1\n"
     ]
    }
   ],
   "source": [
    "for x_batch, y_batch in train_ds.take(1):\n",
    "    print(f\"Shapes X: {x_batch.shape}, Y: {y_batch.shape}\")\n",
    "    print(f\"1st Element: {x_batch[0]}, Y: {y_batch[0]}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OLYVMS-PlZio"
   },
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dJMdqCyIlZRK"
   },
   "outputs": [],
   "source": [
    "def create_model(vocab_size, num_labels, vectorizer=None):\n",
    "    my_layers = []\n",
    "    if vectorizer:\n",
    "        my_layers.append(vectorizer)\n",
    "\n",
    "    my_layers.extend([\n",
    "            tf.keras.layers.Embedding(vocab_size, 64, mask_zero=True),\n",
    "            tf.keras.layers.Dropout(0.5),\n",
    "            tf.keras.layers.Conv1D(64, 5, padding='valid', activation='relu', strides=2),\n",
    "            tf.keras.layers.GlobalAveragePooling1D(),\n",
    "            tf.keras.layers.Dense(num_labels),\n",
    "        ]\n",
    "    )\n",
    "    model = tf.keras.Sequential(my_layers)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "65bKVd9-nef_"
   },
   "source": [
    "The custom text vectorizer adds 0 for padding and n+1 for out-of-vocabulary (OOV) tokens, hence the vocabulary size increases by two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    },
    "id": "BGCf457Tm85Q",
    "outputId": "204fce82-72aa-45e8-86ec-5fedc9eb2944"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ ?                           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling1d_1           │ ?                           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ ?                           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)                    │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling1d_1           │ ?                           │               \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "NUM_LABELS = 3\n",
    "model = create_model(VOCAB_SIZE+2, NUM_LABELS)\n",
    "\n",
    "model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics = ['acc'],\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O8e-qB2hoDfs",
    "outputId": "2bd7465a-52ed-4401-98ba-682737353419"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:938: UserWarning: Layer 'conv1d_2' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    616/Unknown \u001b[1m45s\u001b[0m 6ms/step - acc: 0.6518 - loss: 0.7185"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 20ms/step - acc: 0.6527 - loss: 0.7170 - val_acc: 0.8252 - val_loss: 0.4326\n",
      "Epoch 2/5\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - acc: 0.8389 - loss: 0.3969 - val_acc: 0.8349 - val_loss: 0.3932\n",
      "Epoch 3/5\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - acc: 0.8683 - loss: 0.3297 - val_acc: 0.8358 - val_loss: 0.3893\n",
      "Epoch 4/5\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - acc: 0.8833 - loss: 0.2899 - val_acc: 0.8378 - val_loss: 0.3912\n",
      "Epoch 5/5\n",
      "\u001b[1m621/621\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - acc: 0.8989 - loss: 0.2544 - val_acc: 0.8390 - val_loss: 0.3956\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data = validation_ds,\n",
    "    epochs = 5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QuOL2j1WolNf"
   },
   "source": [
    "### Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1DdrI6buok3z",
    "outputId": "720f1102-80fd-4d29-b7f0-a54fb281fdfa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.8374 - loss: 0.4018\n",
      "Loss:  0.3956109583377838\n",
      "Accuracy: 83.90%\n"
     ]
    }
   ],
   "source": [
    "metrics = model.evaluate(validation_ds, return_dict=True)\n",
    "\n",
    "print(\"Loss: \", metrics['loss'])\n",
    "print(\"Accuracy: {:2.2%}\".format(metrics['acc']))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
